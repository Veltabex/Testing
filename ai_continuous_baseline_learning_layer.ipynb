{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Continuous Learning IoT Malware Detection System\n",
        "# Building on your existing Random Forest model\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "from collections import deque\n",
        "import joblib\n",
        "import time\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# =============================================================================\n",
        "# PART 1: BASELINE NETWORK PROFILING\n",
        "# =============================================================================\n",
        "\n",
        "class NetworkBaselineProfiler:\n",
        "    \"\"\"\n",
        "    Creates and maintains a baseline of normal network behavior\n",
        "    \"\"\"\n",
        "    def __init__(self, window_size=1000):\n",
        "        self.window_size = window_size\n",
        "        self.baseline_stats = {}\n",
        "        self.feature_names = None\n",
        "        self.history = deque(maxlen=window_size)\n",
        "\n",
        "    def initialize_baseline(self, normal_data):\n",
        "        \"\"\"\n",
        "        Initialize baseline with known normal traffic\n",
        "        normal_data: DataFrame with normal network features\n",
        "        \"\"\"\n",
        "        print(\"Initializing network baseline...\")\n",
        "        self.feature_names = list(normal_data.columns)\n",
        "\n",
        "        # Calculate statistical baseline for each feature\n",
        "        for feature in self.feature_names:\n",
        "            self.baseline_stats[feature] = {\n",
        "                'mean': normal_data[feature].mean(),\n",
        "                'std': normal_data[feature].std(),\n",
        "                'min': normal_data[feature].min(),\n",
        "                'max': normal_data[feature].max(),\n",
        "                'q1': normal_data[feature].quantile(0.25),\n",
        "                'q3': normal_data[feature].quantile(0.75)\n",
        "            }\n",
        "\n",
        "        # Store initial samples\n",
        "        for _, row in normal_data.iterrows():\n",
        "            self.history.append(row.values)\n",
        "\n",
        "        print(f\"Baseline initialized with {len(normal_data)} samples\")\n",
        "\n",
        "    def update_baseline(self, new_sample, is_normal=True):\n",
        "        \"\"\"\n",
        "        Update baseline with new normal samples\n",
        "        \"\"\"\n",
        "        if is_normal:\n",
        "            self.history.append(new_sample)\n",
        "\n",
        "            # Recalculate statistics every 100 samples\n",
        "            if len(self.history) % 100 == 0:\n",
        "                recent_data = pd.DataFrame(list(self.history), columns=self.feature_names)\n",
        "                for feature in self.feature_names:\n",
        "                    self.baseline_stats[feature]['mean'] = recent_data[feature].mean()\n",
        "                    self.baseline_stats[feature]['std'] = recent_data[feature].std()\n",
        "\n",
        "    def calculate_anomaly_score(self, sample):\n",
        "        \"\"\"\n",
        "        Calculate how anomalous a sample is compared to baseline\n",
        "        Returns score between 0 (normal) and 1 (highly anomalous)\n",
        "        \"\"\"\n",
        "        anomaly_scores = []\n",
        "\n",
        "        for i, feature in enumerate(self.feature_names):\n",
        "            value = sample[i]\n",
        "            stats = self.baseline_stats[feature]\n",
        "\n",
        "            # Z-score based anomaly\n",
        "            if stats['std'] > 0:\n",
        "                z_score = abs((value - stats['mean']) / stats['std'])\n",
        "                anomaly_scores.append(min(z_score / 3, 1))  # Normalize to 0-1\n",
        "            else:\n",
        "                anomaly_scores.append(0)\n",
        "\n",
        "        return np.mean(anomaly_scores)\n",
        "\n",
        "# =============================================================================\n",
        "# PART 2: CONTINUOUS LEARNING DETECTOR\n",
        "# =============================================================================\n",
        "\n",
        "class ContinuousLearningDetector:\n",
        "    \"\"\"\n",
        "    IoT malware detector with continuous learning capabilities\n",
        "    \"\"\"\n",
        "    def __init__(self, base_model, scaler, feature_columns, retrain_threshold=500):\n",
        "        self.model = base_model\n",
        "        self.scaler = scaler\n",
        "        self.feature_columns = feature_columns\n",
        "        self.retrain_threshold = retrain_threshold\n",
        "\n",
        "        # Continuous learning components\n",
        "        self.new_samples = []\n",
        "        self.new_labels = []\n",
        "        self.performance_history = []\n",
        "        self.model_versions = []\n",
        "        self.false_positives = []\n",
        "        self.false_negatives = []\n",
        "\n",
        "        # Drift detection\n",
        "        self.baseline_profiler = NetworkBaselineProfiler()\n",
        "        self.drift_threshold = 0.3\n",
        "\n",
        "        # Save initial model\n",
        "        self.model_versions.append({\n",
        "            'version': 0,\n",
        "            'timestamp': datetime.now(),\n",
        "            'model': joblib.dumps(self.model),\n",
        "            'performance': {'accuracy': 1.0, 'f1': 1.0}\n",
        "        })\n",
        "\n",
        "    def predict_with_confidence(self, sample):\n",
        "        \"\"\"\n",
        "        Predict with confidence score and anomaly detection\n",
        "        \"\"\"\n",
        "        # Scale the sample\n",
        "        sample_scaled = self.scaler.transform([sample])\n",
        "\n",
        "        # Get prediction and probability\n",
        "        prediction = self.model.predict(sample_scaled)[0]\n",
        "        prob = self.model.predict_proba(sample_scaled)[0]\n",
        "        confidence = max(prob)\n",
        "\n",
        "        # Calculate anomaly score\n",
        "        anomaly_score = self.baseline_profiler.calculate_anomaly_score(sample)\n",
        "\n",
        "        # Adjust confidence based on anomaly\n",
        "        if anomaly_score > self.drift_threshold:\n",
        "            confidence *= (1 - anomaly_score/2)  # Reduce confidence for anomalies\n",
        "\n",
        "        return {\n",
        "            'prediction': prediction,\n",
        "            'confidence': confidence,\n",
        "            'anomaly_score': anomaly_score,\n",
        "            'probabilities': prob\n",
        "        }\n",
        "\n",
        "    def add_feedback(self, sample, true_label, predicted_label):\n",
        "        \"\"\"\n",
        "        Add user feedback for continuous learning\n",
        "        \"\"\"\n",
        "        self.new_samples.append(sample)\n",
        "        self.new_labels.append(true_label)\n",
        "\n",
        "        # Track errors for learning\n",
        "        if true_label != predicted_label:\n",
        "            if predicted_label == 1 and true_label == 0:\n",
        "                self.false_positives.append(sample)\n",
        "            elif predicted_label == 0 and true_label == 1:\n",
        "                self.false_negatives.append(sample)\n",
        "\n",
        "        # Update baseline if normal\n",
        "        if true_label == 0:\n",
        "            self.baseline_profiler.update_baseline(sample, is_normal=True)\n",
        "\n",
        "        # Check if retraining needed\n",
        "        if len(self.new_samples) >= self.retrain_threshold:\n",
        "            self.retrain_model()\n",
        "\n",
        "    def retrain_model(self):\n",
        "        \"\"\"\n",
        "        Retrain model with accumulated samples\n",
        "        \"\"\"\n",
        "        print(f\"\\nRetraining model with {len(self.new_samples)} new samples...\")\n",
        "\n",
        "        # Combine with recent false positives/negatives for focused learning\n",
        "        X_new = np.array(self.new_samples)\n",
        "        y_new = np.array(self.new_labels)\n",
        "\n",
        "        # Add recent errors with higher weight\n",
        "        if len(self.false_positives) > 0:\n",
        "            fp_samples = self.false_positives[-50:]  # Last 50 FPs\n",
        "            X_new = np.vstack([X_new] + [fp_samples] * 2)  # Weight 2x\n",
        "            y_new = np.concatenate([y_new] + [[0] * len(fp_samples)] * 2)\n",
        "\n",
        "        if len(self.false_negatives) > 0:\n",
        "            fn_samples = self.false_negatives[-50:]  # Last 50 FNs\n",
        "            X_new = np.vstack([X_new] + [fn_samples] * 3)  # Weight 3x (more critical)\n",
        "            y_new = np.concatenate([y_new] + [[1] * len(fn_samples)] * 3)\n",
        "\n",
        "        # Scale new data\n",
        "        X_new_scaled = self.scaler.transform(X_new)\n",
        "\n",
        "        # Incremental learning (warm start)\n",
        "        self.model.n_estimators += 10  # Add more trees\n",
        "        self.model.fit(X_new_scaled, y_new)\n",
        "\n",
        "        # Evaluate on recent data\n",
        "        if len(self.new_samples) > 100:\n",
        "            X_eval = self.scaler.transform(self.new_samples[-100:])\n",
        "            y_eval = self.new_labels[-100:]\n",
        "            accuracy = accuracy_score(y_eval, self.model.predict(X_eval))\n",
        "            f1 = f1_score(y_eval, self.model.predict(X_eval), average='weighted')\n",
        "\n",
        "            self.performance_history.append({\n",
        "                'timestamp': datetime.now(),\n",
        "                'accuracy': accuracy,\n",
        "                'f1': f1,\n",
        "                'samples_trained': len(self.new_samples)\n",
        "            })\n",
        "\n",
        "            print(f\"Retrained model performance: Accuracy={accuracy:.4f}, F1={f1:.4f}\")\n",
        "\n",
        "        # Save model version\n",
        "        self.model_versions.append({\n",
        "            'version': len(self.model_versions),\n",
        "            'timestamp': datetime.now(),\n",
        "            'model': joblib.dumps(self.model),\n",
        "            'performance': {'accuracy': accuracy, 'f1': f1}\n",
        "        })\n",
        "\n",
        "        # Clear training buffer\n",
        "        self.new_samples = []\n",
        "        self.new_labels = []\n",
        "\n",
        "    def detect_concept_drift(self, recent_predictions, window_size=100):\n",
        "        \"\"\"\n",
        "        Detect if the network behavior has significantly changed\n",
        "        \"\"\"\n",
        "        if len(recent_predictions) < window_size:\n",
        "            return False\n",
        "\n",
        "        recent = recent_predictions[-window_size:]\n",
        "        anomaly_scores = [p['anomaly_score'] for p in recent]\n",
        "\n",
        "        # High average anomaly score indicates drift\n",
        "        avg_anomaly = np.mean(anomaly_scores)\n",
        "        if avg_anomaly > self.drift_threshold:\n",
        "            print(f\"⚠️  Concept drift detected! Average anomaly score: {avg_anomaly:.3f}\")\n",
        "            return True\n",
        "\n",
        "        return False\n",
        "\n",
        "# =============================================================================\n",
        "# PART 3: REAL-TIME MONITORING SYSTEM\n",
        "# =============================================================================\n",
        "\n",
        "class IoTMalwareMonitor:\n",
        "    \"\"\"\n",
        "    Complete monitoring system for deployment\n",
        "    \"\"\"\n",
        "    def __init__(self, model_path, scaler_path, feature_columns):\n",
        "        # Load pre-trained model\n",
        "        self.base_model = joblib.load(model_path)\n",
        "        self.scaler = joblib.load(scaler_path)\n",
        "\n",
        "        # Initialize continuous learning detector\n",
        "        self.detector = ContinuousLearningDetector(\n",
        "            self.base_model,\n",
        "            self.scaler,\n",
        "            feature_columns,\n",
        "            retrain_threshold=500\n",
        "        )\n",
        "\n",
        "        # Monitoring state\n",
        "        self.alerts = []\n",
        "        self.predictions_cache = deque(maxlen=1000)\n",
        "        self.start_time = datetime.now()\n",
        "\n",
        "    def initialize_household_baseline(self, normal_traffic_df):\n",
        "        \"\"\"\n",
        "        Initialize with household's normal traffic patterns\n",
        "        \"\"\"\n",
        "        print(\"Learning household network patterns...\")\n",
        "        self.detector.baseline_profiler.initialize_baseline(normal_traffic_df)\n",
        "        print(\"✅ Baseline established\")\n",
        "\n",
        "    def monitor_traffic(self, traffic_sample):\n",
        "        \"\"\"\n",
        "        Main monitoring function - call this for each network sample\n",
        "        Returns: (is_malware, confidence, should_alert)\n",
        "        \"\"\"\n",
        "        # Get prediction with confidence\n",
        "        result = self.detector.predict_with_confidence(traffic_sample)\n",
        "\n",
        "        # Cache for drift detection\n",
        "        self.predictions_cache.append(result)\n",
        "\n",
        "        # Determine if alert needed\n",
        "        should_alert = False\n",
        "        if result['prediction'] == 1:  # Malware detected\n",
        "            if result['confidence'] > 0.7:  # High confidence\n",
        "                should_alert = True\n",
        "                self.alerts.append({\n",
        "                    'timestamp': datetime.now(),\n",
        "                    'confidence': result['confidence'],\n",
        "                    'anomaly_score': result['anomaly_score'],\n",
        "                    'sample': traffic_sample\n",
        "                })\n",
        "\n",
        "        # Check for concept drift\n",
        "        if len(self.predictions_cache) % 100 == 0:\n",
        "            if self.detector.detect_concept_drift(list(self.predictions_cache)):\n",
        "                print(\"🔄 Adapting to network changes...\")\n",
        "\n",
        "        return result['prediction'], result['confidence'], should_alert\n",
        "\n",
        "    def provide_feedback(self, sample_id, true_label):\n",
        "        \"\"\"\n",
        "        User feedback for false positives/negatives\n",
        "        \"\"\"\n",
        "        # In real deployment, you'd track sample IDs\n",
        "        # For demo, use last prediction\n",
        "        if self.predictions_cache:\n",
        "            last_sample = self.alerts[-1]['sample'] if self.alerts else None\n",
        "            if last_sample is not None:\n",
        "                predicted = self.predictions_cache[-1]['prediction']\n",
        "                self.detector.add_feedback(last_sample, true_label, predicted)\n",
        "                print(f\"✅ Feedback recorded. Model will adapt.\")\n",
        "\n",
        "    def get_system_status(self):\n",
        "        \"\"\"\n",
        "        Get current system status and statistics\n",
        "        \"\"\"\n",
        "        uptime = datetime.now() - self.start_time\n",
        "        return {\n",
        "            'uptime': str(uptime),\n",
        "            'total_samples': len(self.predictions_cache),\n",
        "            'alerts_raised': len(self.alerts),\n",
        "            'model_version': len(self.detector.model_versions) - 1,\n",
        "            'last_retrain': self.detector.model_versions[-1]['timestamp'],\n",
        "            'current_performance': self.detector.model_versions[-1]['performance'],\n",
        "            'false_positives': len(self.detector.false_positives),\n",
        "            'false_negatives': len(self.detector.false_negatives)\n",
        "        }\n",
        "\n",
        "# =============================================================================\n",
        "# PART 4: DEPLOYMENT SCRIPT\n",
        "# =============================================================================\n",
        "\n",
        "def deploy_continuous_monitor():\n",
        "    \"\"\"\n",
        "    Deploy the continuous learning monitor\n",
        "    \"\"\"\n",
        "    print(\"🚀 Deploying IoT Malware Monitor with Continuous Learning\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Load your trained model and scaler\n",
        "    # Replace with your actual paths\n",
        "    MODEL_PATH = 'iot_malware_rf_model.pkl'\n",
        "    SCALER_PATH = 'iot_malware_scaler.pkl'\n",
        "\n",
        "    # Use your selected features\n",
        "    FEATURE_COLUMNS = ['HH_jit_L0_1_mean', 'HH_jit_L0_01_mean', 'HpHp_L0_01_radius',\n",
        "                       'H_L0_01_weight', 'MI_dir_L0_1_weight']  # ... add all 30\n",
        "\n",
        "    # Initialize monitor\n",
        "    monitor = IoTMalwareMonitor(MODEL_PATH, SCALER_PATH, FEATURE_COLUMNS)\n",
        "\n",
        "    # Simulate initialization with household baseline\n",
        "    # In real deployment, collect ~1 hour of normal traffic\n",
        "    print(\"\\n📊 Establishing household baseline...\")\n",
        "    # normal_traffic = load_normal_household_traffic()  # Your function\n",
        "    # monitor.initialize_household_baseline(normal_traffic)\n",
        "\n",
        "    print(\"\\n✅ System Ready! Monitoring network traffic...\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Simulation of real-time monitoring\n",
        "    malware_count = 0\n",
        "    sample_count = 0\n",
        "\n",
        "    # In real deployment, this would be a continuous loop\n",
        "    # reading from network interface\n",
        "    while True:\n",
        "        try:\n",
        "            # Get next network sample (replace with actual network capture)\n",
        "            # traffic_sample = capture_network_features()  # Your function\n",
        "\n",
        "            # For demo, simulate with random sample\n",
        "            traffic_sample = np.random.randn(30)  # Replace with real data\n",
        "\n",
        "            # Monitor the traffic\n",
        "            is_malware, confidence, should_alert = monitor.monitor_traffic(traffic_sample)\n",
        "\n",
        "            sample_count += 1\n",
        "            if is_malware:\n",
        "                malware_count += 1\n",
        "\n",
        "            # Alert on high-confidence malware\n",
        "            if should_alert:\n",
        "                print(f\"\\n🚨 MALWARE DETECTED! Confidence: {confidence:.2%}\")\n",
        "                print(f\"   Total detections: {malware_count}/{sample_count}\")\n",
        "\n",
        "            # Periodic status update\n",
        "            if sample_count % 1000 == 0:\n",
        "                status = monitor.get_system_status()\n",
        "                print(f\"\\n📈 Status Update:\")\n",
        "                print(f\"   Samples processed: {status['total_samples']}\")\n",
        "                print(f\"   Alerts: {status['alerts_raised']}\")\n",
        "                print(f\"   Model version: {status['model_version']}\")\n",
        "\n",
        "            # Simulate delay\n",
        "            time.sleep(0.1)  # In real deployment, remove this\n",
        "\n",
        "        except KeyboardInterrupt:\n",
        "            print(\"\\n\\n🛑 Monitoring stopped by user\")\n",
        "            break\n",
        "        except Exception as e:\n",
        "            print(f\"\\n❌ Error: {e}\")\n",
        "            continue\n",
        "\n",
        "    # Save final model\n",
        "    print(\"\\n💾 Saving adapted model...\")\n",
        "    final_model = monitor.detector.model\n",
        "    joblib.dump(final_model, 'iot_malware_adapted_model.pkl')\n",
        "\n",
        "    # Print final statistics\n",
        "    final_status = monitor.get_system_status()\n",
        "    print(\"\\n📊 Final Statistics:\")\n",
        "    for key, value in final_status.items():\n",
        "        print(f\"   {key}: {value}\")\n",
        "\n",
        "# =============================================================================\n",
        "# USAGE EXAMPLE\n",
        "# =============================================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # For testing in Colab\n",
        "    print(\"Continuous Learning IoT Malware Detector\")\n",
        "    print(\"This system will:\")\n",
        "    print(\"1. Learn your household's normal network patterns\")\n",
        "    print(\"2. Continuously monitor for malware\")\n",
        "    print(\"3. Adapt to new threats automatically\")\n",
        "    print(\"4. Reduce false positives over time\")\n",
        "\n",
        "    # To deploy:\n",
        "    # deploy_continuous_monitor()\n",
        "\n",
        "    # For testing with your existing model:\n",
        "    # 1. Load your trained RF model and scaler\n",
        "    # 2. Create some test normal/malware samples\n",
        "    # 3. Initialize the continuous learning detector\n",
        "    # 4. Simulate monitoring and adaptation"
      ],
      "metadata": {
        "id": "Aa09cKQPCdfC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19a21c27"
      },
      "source": [
        "# Task\n",
        "Create a Python application that uses a pre-trained SVM model and scaler located at \"/content/drive/MyDrive/Colab Notebooks/ML_Models/3_SVM_WORKING/Model_V1/iot_malware_svm_subset_model.pkl\" and \"/content/drive/MyDrive/Colab Notebook/ML_Models/3_SVM_WORKING/Model_V1/iot_malware_svm_subset_scaler.pkl\" respectively, to detect IoT malware. The application should implement a combined detection approach that uses both the model's prediction and a baseline anomaly check to reduce false positives. Simulate a real-time data pipeline by reading data from designated folders: one for baseline data and another for live monitoring data. Develop a simple web interface using Flask that displays the system's status (active/loading), provides a button to initiate baseline training with user prompts based on malware detection in the baseline data, and shows real-time prediction results, potentially with basic visualizations."
      ]
    }
  ]
}